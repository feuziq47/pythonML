{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 5  6  7]\n",
      " [ 8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "#quiz1\n",
    "ans=np.arange(2,11).reshape(3,3)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0. 11.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#quiz2\n",
    "ans=np.zeros(10)\n",
    "ans[6]=11\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "#quiz3\n",
    "ans=np.array([1,2,0,0,4,0])\n",
    "tmp=[]\n",
    "for data in ans:\n",
    "    if data!=0:\n",
    "        tmp.append(data)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris=load_iris()\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "train_data=iris.data\n",
    "train_label=iris.target\n",
    "dt_clf.fit(train_data,train_label)\n",
    "pred=dt_clf.predict(train_data)\n",
    "\n",
    "print('prediction accuracy:',accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data Set Size: 150\n"
     ]
    }
   ],
   "source": [
    "#K Fold Cross Validation 1\n",
    "from sklearn.model_selection import KFold\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=142)\n",
    "\n",
    "k_fold=KFold(n_splits=5)\n",
    "cv_accuracy=[]\n",
    "print('Iris Data Set Size:',features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "#K Fold Cross Validation 2\n",
    "fold_index=0\n",
    "for train_index,test_index in k_fold.split(features):\n",
    "    x_train,x_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    print(train_index)\n",
    "    print(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 fold accuracy:1.0, train size:120, test size: 30\n",
      "#1 test index:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "2 fold accuracy:0.9667, train size:120, test size: 30\n",
      "#2 test index:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "3 fold accuracy:0.9, train size:120, test size: 30\n",
      "#3 test index:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "4 fold accuracy:0.9333, train size:120, test size: 30\n",
      "#4 test index:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "5 fold accuracy:0.7667, train size:120, test size: 30\n",
      "#5 test index:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "##avg val accuracy: 0.91334\n"
     ]
    }
   ],
   "source": [
    "#K Fold Cross Validation 3\n",
    "fold_index=0\n",
    "for train_index,test_index in k_fold.split(features):\n",
    "    x_train,x_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    \n",
    "    dt_clf.fit(x_train,y_train)\n",
    "    pred=dt_clf.predict(x_test)\n",
    "    fold_index+=1\n",
    "    \n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=x_train.shape[0]\n",
    "    test_size=x_test.shape[0]\n",
    "    \n",
    "    print('\\n{0} fold accuracy:{1}, train size:{2}, test size: {3}'.format(fold_index,accuracy,train_size,test_size))\n",
    "    print('#{0} test index:{1}'.format(fold_index,test_index))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "print('\\n##avg val accuracy:',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Cross Validation:1\n",
      "Train label distribution:\n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "Val label distribution:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "##Cross Validation:2\n",
      "Train label distribution:\n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "Val label distribution:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "##Cross Validation:3\n",
      "Train label distribution:\n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "Val label distribution:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#K Fold Cross Validation 의 한계1\n",
    "import pandas as pd\n",
    "iris=load_iris()\n",
    "df_iris=pd.DataFrame(data=iris.data,columns=iris.feature_names)\n",
    "df_iris['label']=iris.target\n",
    "df_iris['label'].value_counts()\n",
    "\n",
    "kfold=KFold(n_splits=3)\n",
    "fold_index=0\n",
    "for train_index,test_index in kfold.split(df_iris):\n",
    "    fold_index+=1\n",
    "    label_train=df_iris['label'].iloc[train_index]\n",
    "    label_test=df_iris['label'].iloc[test_index]\n",
    "    print('##Cross Validation:{0}'.format(fold_index))\n",
    "    print('Train label distribution:\\n',label_train.value_counts())\n",
    "    print('Val label distribution:\\n',label_test.value_counts())\n",
    "#train set과 validation set의 label 분포가 완전히 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data Set Size: 150\n",
      "\n",
      "1 fold accuracy:0.84, train size:100, test size: 50\n",
      "#1 test index:[  6   7   8   9  22  24  25  27  29  30  37  40  41  49  50  52  53  55\n",
      "  60  61  62  65  76  77  79  82  84  86  87  89  93  97  98  99 102 107\n",
      " 110 113 118 120 125 129 130 133 134 136 137 139 141 149]\n",
      "\n",
      "2 fold accuracy:0.92, train size:100, test size: 50\n",
      "#2 test index:[  3   4   5  10  11  15  17  18  19  20  23  32  35  38  42  45  46  47\n",
      "  48  57  58  63  64  67  68  70  71  72  75  81  83  85  94  96 100 104\n",
      " 106 108 109 114 116 117 119 121 123 132 135 142 143 146]\n",
      "\n",
      "3 fold accuracy:0.96, train size:100, test size: 50\n",
      "#3 test index:[  0   1   2  12  13  14  16  21  26  28  31  33  34  36  39  43  44  51\n",
      "  54  56  59  66  69  73  74  78  80  88  90  91  92  95 101 103 105 111\n",
      " 112 115 122 124 126 127 128 131 138 140 144 145 147 148]\n",
      "\n",
      "##avg val accuracy: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "##K Fold Cross Validation 의 한계2\n",
    "from sklearn.model_selection import KFold\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=142)\n",
    "\n",
    "k_fold=KFold(n_splits=3,shuffle=True)\n",
    "cv_accuracy=[]\n",
    "print('Iris Data Set Size:',features.shape[0])\n",
    "fold_index=0\n",
    "for train_index,test_index in k_fold.split(features):\n",
    "    x_train,x_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    \n",
    "    dt_clf.fit(x_train,y_train)\n",
    "    pred=dt_clf.predict(x_test)\n",
    "    fold_index+=1\n",
    "    \n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=x_train.shape[0]\n",
    "    test_size=x_test.shape[0]\n",
    "    \n",
    "    print('\\n{0} fold accuracy:{1}, train size:{2}, test size: {3}'.format(fold_index,accuracy,train_size,test_size))\n",
    "    print('#{0} test index:{1}'.format(fold_index,test_index))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "print('\\n##avg val accuracy:',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1Cross val accuacy:0.9804, train size:99, test size:99\n",
      "#1Val index:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116]\n",
      "\n",
      "#2Cross val accuacy:0.9216, train size:99, test size:99\n",
      "#2Val index:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]\n",
      "\n",
      "#3Cross val accuacy:0.9792, train size:102, test size:102\n",
      "#3Val index:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "##fold val accuracy: [0.9804 0.9216 0.9792]\n",
      "##avg val accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "#Stratified K Fold Cross Validation2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "df_clf=DecisionTreeClassifier(random_state=120)\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "fold_index=0\n",
    "lst_accuracy=[]\n",
    "\n",
    "for train_index,test_index in skfold.split(features,label):\n",
    "    x_train,x_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index],label[test_index]\n",
    "    dt_clf.fit(x_train,y_train)\n",
    "    pred=dt_clf.predict(x_test)\n",
    "    fold_index+=1\n",
    "    accuracy=np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size=x_train.shape[0]\n",
    "    test_size=y_train.shape[0]\n",
    "    print('\\n#{0}Cross val accuacy:{1}, train size:{2}, test size:{3}'.format(fold_index,accuracy,train_size,test_size))\n",
    "    print('#{0}Val index:{1}'.format(fold_index,test_index))\n",
    "    lst_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n##fold val accuracy:',np.round(lst_accuracy,4))\n",
    "print('##avg val accuracy:',np.mean(lst_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold val accuracy: [0.9804 0.9216 1.    ]\n",
      "Avg val accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "#cross_val_score API\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "iris=load_iris()\n",
    "dt_clf=DecisionTreeClassifier(random_state=1923)\n",
    "data=iris.data\n",
    "label=iris.target\n",
    "scores=cross_val_score(dt_clf,data,label,scoring='accuracy',cv=3)\n",
    "print('Fold val accuracy:',np.round(scores,4))\n",
    "print('Avg val accuracy:',np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00066463, 0.00032234, 0.00033132, 0.        , 0.00033236,\n",
      "       0.00066392]), 'std_fit_time': array([0.00046997, 0.00045586, 0.00046856, 0.        , 0.00047002,\n",
      "       0.00046946]), 'mean_score_time': array([0.        , 0.00067568, 0.000676  , 0.        , 0.        ,\n",
      "       0.00033315]), 'std_score_time': array([0.        , 0.00047797, 0.00047829, 0.        , 0.        ,\n",
      "       0.00047115]), 'param_max_depth': masked_array(data=[1, 1, 2, 2, 3, 3],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1, 'min_samples_split': 2}, {'max_depth': 1, 'min_samples_split': 3}, {'max_depth': 2, 'min_samples_split': 2}, {'max_depth': 2, 'min_samples_split': 3}, {'max_depth': 3, 'min_samples_split': 2}, {'max_depth': 3, 'min_samples_split': 3}], 'split0_test_score': array([0.7  , 0.7  , 0.925, 0.925, 0.975, 0.975]), 'split1_test_score': array([0.7, 0.7, 1. , 1. , 1. , 1. ]), 'split2_test_score': array([0.7 , 0.7 , 0.95, 0.95, 0.95, 0.95]), 'mean_test_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.975     ,\n",
      "       0.975     ]), 'std_test_score': array([0.        , 0.        , 0.03118048, 0.03118048, 0.02041241,\n",
      "       0.02041241]), 'rank_test_score': array([5, 5, 3, 3, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV() API1\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris=load_iris()\n",
    "x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.2,random_state=121)\n",
    "dtree=DecisionTreeClassifier()\n",
    "parameters={'max_depth':[1,2,3],'min_samples_split':[2,3]}\n",
    "\n",
    "import pandas as pd\n",
    "grid_dtree=GridSearchCV(dtree,param_grid=parameters,cv=3,refit=True)\n",
    "grid_dtree.fit(x_train,y_train)\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameter: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Max accuracy:0.9750\n"
     ]
    }
   ],
   "source": [
    "##GridSearchCV() API2: 최적의 파라미터 정보확인\n",
    "print('Optimal parameter:',grid_dtree.best_params_)\n",
    "print('Max accuracy:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test datast accuracy:0.9667\n"
     ]
    }
   ],
   "source": [
    "##GridSearch() API3 : 최적의 파라미터로 학습된 모델의 성능검증\n",
    "estimator=grid_dtree.best_estimator_\n",
    "pred=estimator.predict(x_test)\n",
    "print('Test datast accuracy:{0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding result: [0 1 4 5 3 3 2 2]\n",
      "Encoding classes: ['TV' '냉장고' '믹서' '선풍기' '전자렌지' '컴퓨터']\n",
      "Decoding values: ['전자렌지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "#Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels=encoder.transform(items)\n",
    "print('Label encoding result:',labels)\n",
    "print('Encoding classes:',encoder.classes_)\n",
    "print('Decoding values:',encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 3)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (6, 2)\t1.0\n",
      "  (7, 2)\t1.0\n",
      "OneHot Encoder Data\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "Dimension of Encoding Data\n",
      "(8, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sun\\venv\\ml\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#One-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels=encoder.transform(items)\n",
    "labels=labels.reshape(-1,1) # -1은 어느 인덱스도 될수있다는 의미\n",
    "\n",
    "one_hot_encoder=OneHotEncoder()\n",
    "one_hot_encoder.fit(labels)\n",
    "one_hot_labels=one_hot_encoder.transform(labels)\n",
    "print('OneHot Encoder Data')\n",
    "print(one_hot_labels.toarray())\n",
    "print('Dimension of Encoding Data')\n",
    "print(one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자렌지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자렌지  item_컴퓨터\n",
       "0        1         0        0         0          0         0\n",
       "1        0         1        0         0          0         0\n",
       "2        0         0        0         0          1         0\n",
       "3        0         0        0         0          0         1\n",
       "4        0         0        0         1          0         0\n",
       "5        0         0        0         1          0         0\n",
       "6        0         0        1         0          0         0\n",
       "7        0         0        1         0          0         0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas를 이용한 one-hot-encoding\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'item':['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "Variance sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Scaling : 특이값 처리를 위해 데이터 값의 범위를 일정한 수준으로 변환\n",
    "#1.StandardScaler() api 1\n",
    "#데이터 값 확인\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris=load_iris()\n",
    "iris_data=iris.data\n",
    "df_iris=pd.DataFrame(data=iris_data,columns=iris.feature_names)\n",
    "\n",
    "print('Average',df_iris.mean())\n",
    "print('\\nVariance',df_iris.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "Variance sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#1.StandardScaler() api2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(df_iris)\n",
    "scaled_iris=scaler.transform(df_iris)\n",
    "df_scaled_iris=pd.DataFrame(data=scaled_iris,columns=iris.feature_names)\n",
    "print('Average',df_scaled_iris.mean())\n",
    "print('\\nVariance',df_scaled_iris.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "Max value sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n",
      "\n",
      "Average value sepal length (cm)    0.428704\n",
      "sepal width (cm)     0.440556\n",
      "petal length (cm)    0.467458\n",
      "petal width (cm)     0.458056\n",
      "dtype: float64\n",
      "\n",
      "Variance value sepal length (cm)    0.052908\n",
      "sepal width (cm)     0.032983\n",
      "petal length (cm)    0.089522\n",
      "petal width (cm)     0.100869\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#2. MInMaxScaler() api\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(df_iris)\n",
    "scaled_iris=scaler.transform(df_iris)\n",
    "df_scaled_iris=pd.DataFrame(data=scaled_iris,columns=iris.feature_names)\n",
    "print('Min value',df_scaled_iris.min())\n",
    "print('\\nMax value',df_scaled_iris.max())\n",
    "print('\\nAverage value',df_scaled_iris.mean())\n",
    "print('\\nVariance value',df_scaled_iris.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-e30ba8b2038b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tit=load(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
